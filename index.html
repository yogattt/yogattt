<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hello World">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hello World">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="yogattt">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hello World</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hello World</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/15/Memory-Augmented-Multi-Instance-Contrastive-Predictive-Coding-for-Sequential-Recommendation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/15/Memory-Augmented-Multi-Instance-Contrastive-Predictive-Coding-for-Sequential-Recommendation/" class="post-title-link" itemprop="url">Memory Augmented Multi-Instance Contrastive Predictive Coding for Sequential Recommendation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-12-15 16:29:27 / Modified: 21:37:26" itemprop="dateCreated datePublished" datetime="2021-12-15T16:29:27+08:00">2021-12-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="abstract">Abstract</h2>
<p>  目前大多数序列推荐模型将下一个item预测任务作为训练信号。对于这些方法，有两个至关重要的挑战 1）难以捕捉用户的长期偏好。2）监督信号过于稀疏而无法有效训练模型。因此作者提出了一个名为MMInfoRec,基于记忆增强的多实例对比预测编码方案的框架来克服这些挑战。基本对比预测编码（Contrastive Predictive Code CPC）作为序列和item的编码器（encoder）.记忆模块旨在增强CPC中的自回归预测，以实现灵活和整体上（general）的偏好编码表示,从而提高捕获长期偏好的能力。为了有效训练MMInfoRec,作者提出了一个新颖的多实例噪声对比估计损失（muti-instance noise constrastive estimation MINCE）.该损失通过使用多个正样本来有效利用mini-bath内的样本。作者提出的框架属于对比学习类型。然而，鉴于其对比训练任务与目标推荐任务很好地对齐，因此不需要进一步地微调步骤。通过对四个基准数据集的大量实验，MMInfoRec 可以胜过最先进的基线。</p>
<h2 id="method">Method</h2>
<figure>
<img src="figure1_overview.png" alt="图1：Overview of MMInfoRec" /><figcaption aria-hidden="true">图1：Overview of MMInfoRec</figcaption>
</figure>
<h3 id="learning-framework"><strong>Learning Framework</strong></h3>
<p>  MMInfoRec的整体架构如图1所示。首先将序列中的所有item的id和attributes分别由两个嵌入层转换为密集特征向量。对于每一个item,它的特征由属性编码器 <span class="math inline">\(g_{enc}\)</span> 编码为潜在表示 <span class="math inline">\(\boldsymbol z\)</span>。时间聚合模块(Temporal aggegation) <span class="math inline">\(g_{ta}\)</span> 将序列信息编码为<span class="math inline">\(\boldsymbol c_t\)</span>。通过自回归预测模块<span class="math inline">\(g_{ap}\)</span>，<span class="math inline">\(\boldsymbol c_t\)</span> 可用于预测未来的潜在表示。</p>
<p>1）<strong>Embedding Layyer</strong>：通过两个emdedding 矩阵：an item embedding matrix <span class="math inline">\(\boldsymbol {Emb_i}\in \mathbb{R}^{\rvert \mathcal{I} \rvert \times d}\)</span>,an attribute embedding matrix <span class="math inline">\(\boldsymbol {Emb_A}\in \mathbb{R}^{\rvert \mathcal{A} \rvert \times d}\)</span>。(其中 <span class="math inline">\(\rvert \mathcal{I} \rvert\)</span> 为item的数量，<span class="math inline">\(\rvert \mathcal{A} \rvert\)</span> 为数据集合中出现的item的属性的数量)将IDs和 attributes 转换为密集向量。 例如，物品 <span class="math inline">\(I_n\)</span> 及其属性<span class="math inline">\(\{ a_1,a_2\}\)</span>,通过lookup操作获得向量: <span class="math inline">\(\bf x_n= \boldsymbol {Emb_i}(i_n)\)</span>,<span class="math inline">\(\boldsymbol a_1= \boldsymbol {Emb_A}(a_1)\)</span>,<span class="math inline">\(\boldsymbol a_2= \boldsymbol {Emb_A}(a_2)\)</span></p>
<p>2）<strong>Attribute Encoder</strong> :旨在将项目的所有信息（包括 ID 信息和属性信息）融合为潜在表示 $_{enc}$的实现，简单的mean,或AutoInt,或item embedding到所有attribute embedding 的self attention 都适用于这个结构。</p>
<p>3）<strong>Temporal aggegation</strong>:时间聚合函数<span class="math inline">\(\it g_{ta}\)</span>用于聚合在某个特定时间之前的item Temporal 信息,得到context　vector。 <span class="math display">\[ \bf c_t = \it g_{ta}(\bf z_1,\bf z_2,...,\bf z_t)\]</span> 其中$_t^{1d} $。可选择GRU或Attention作为时间聚合函数。</p>
<p>4）<strong>Memory Module</strong>:增强模型的表示能力，作者设计了一个记忆模块，根据context vector计算每一步的预测输出。记忆模块中有一个带有b个内存条的内存库 <span class="math inline">\(\bf M\in\mathbb{R}^{b \times d}\)</span> 内存寻址操作定义如下: <span class="math display">\[\hat {\bf z}_{t+1} = \it g_m(\bf c_t) \]</span> <span class="math display">\[=Softmax(MLP(\bf c_t)) \cdot\bf M + \bf c_t \]</span> 残差旨在保留原始预测并改进训练中的梯度流。</p>
<p>5）<strong>Auto-regressive Prediction</strong>:对于多步预测任务，如果上下文被编码为向量 <span class="math inline">\(\bf c_t\)</span> ,那么预测的潜在表示 <span class="math inline">\(\hat{\bf z}_{t+*}\)</span> 预计与 <span class="math inline">\(\bf c_t\)</span> 有很强的语义相似性。因此，我们引入自回归预测函数<span class="math inline">\(\it g_{ap}\)</span> <span class="math display">\[\bf c_{t+1}=\it g_{ap}(\hat{\bf z}_{t+1}),\ \ \hat{\bf z}_{t+2} = \it g_m(\bf c_{t+1})\]</span> 其中 <span class="math inline">\(\bf c_{t+1}\)</span> 是时间步骤1到t+1的上下文摘要， <span class="math inline">\(\hat{\bf z}_{t+2}\)</span> 是时间步骤 t + 2 的预测特征。类似于 Seq2Seq 预测风潜在表示以顺序方式一一预测。</p>
<p>6）<strong>Recommendation</strong>:在MMInfoRec的验证和测试过程中，推荐是在序列表示 <span class="math inline">\(\bf c_t\)</span> 和项目集中所有项目之间的分的得分排序下进行的。 分数是通过当前时间步长 t 的序列表示 <span class="math inline">\(\bf c_t\)</span> 与项目集中所有项目的潜在表示 <span class="math inline">\(\mathbf{z}\)</span> 之间的点积计算得出的。</p>
<h3 id="contrastive-loss"><strong>Contrastive Loss</strong></h3>
<p>Noise Contrastive Estimation (NCE) 是一种分类目标，可以区分真实样本和噪声样本。NCE 损失可以直接应用于项目预测任务。 在 MMInfoRec 中，作者将此损失扩展到多实例变体，可以有效缓解训练信号稀疏的问题。</p>
<p>1）<strong>Vanilla NCE Loss</strong>：vanilla NCE 主要对潜在空间中的表示进行比较，以迫使预测表示 <span class="math inline">\(\hat {\bf z }\)</span> 接近真实表示 <span class="math inline">\(\bf z\)</span> <span class="math display">\[\mathcal{L}_{NCE}=-\sum_t\left[log { e^{\left(\hat{\bf z}_t^T\cdot \bf z_t\right)/\tau}\over e^{\left(\hat{\bf z}_t^T\cdot \bf z_t\right)/\tau}+\sum_{*\in\mathcal{N}_i}e\left(\hat{\bf z}_t^T\cdot \bf z_*\right)}\right]\]</span> 其中 <span class="math inline">\(\tau\)</span> 为温度参数，<span class="math inline">\(\mathcal{N}_i\)</span> 是时间为t的item的负样本集。本质上 <span class="math inline">\(\mathcal{L}_{NCE}\)</span> 是一个正样本对和其他所有负样本对之间的交叉熵损失</p>
<p>2）<strong>Negative Sampling within Bath</strong>:因为训练时需要负样本集，因此需要负样本集的采样过程。一般有两种抽样方法：memory bank and batch sampling。在 MMInfoRec 中，NCE 的计算在一个batch内进行，而不是在整个项目集中进行抽样，因为一个batch将包含足够的负样本。 在计算机视觉任务的 CPC 方法中，负样本可以从同一个特征图的通道中选择，也可以从同一批的其他特征图中选择。 类似地，在顺序推荐中，可以使用batch中其他物品的特征向量 <span class="math inline">\(\bf{z}\)</span> 为每个物品i构造负样本集 <span class="math inline">\(\mathcal{N}_i\)</span>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/10/Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/10/Knowledge-Graph-Embedding-by-Translating-on-Hyperplanes/" class="post-title-link" itemprop="url">Knowledge Graph Embedding by Translating on Hyperplanes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-12-10 16:12:08 / Modified: 17:17:11" itemprop="dateCreated datePublished" datetime="2021-12-10T16:12:08+08:00">2021-12-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="abstract">abstract</h2>
<p>  我们通常将由实体和关系组成的知识图谱嵌入到连续的向量空间。TransE就是一种有效的方法。但是对于一些复杂关系的映射属性，如自反性、一对多、多对一和多对多，TransE并不能很好地处理这些属性。一些复杂的模型能够保留这些映射属性，但会在此过程中牺牲效率。 因此作者提出TransH，它将关系建模为超平面,并在其上进行平移操作。该方法能够以与transE几乎相同的复杂性,保留上述的关系映射属性。此外，由于实际知识图谱往往非常不完整，因此如何在训练中构建负例以降低错误负标签是非常重要的。 利用一对多/多对一关系映射属性，作者提出一个简单的技巧来减少错误负标签的可能性。作者在WordNet和Freebase等基准数据集上进行了大量的链接预测、三元组分类和知识抽取实验。实验表明，TransH在预测精度方面比TransE有显著的改进，并且具有可比的扩展能力。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/26/LaTex%E8%A1%A8%E8%BE%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/26/LaTex%E8%A1%A8%E8%BE%BE/" class="post-title-link" itemprop="url">LaTex表达</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-11-26 16:39:01 / Modified: 16:52:35" itemprop="dateCreated datePublished" datetime="2021-11-26T16:39:01+08:00">2021-11-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>命令\overbrace 和\underbrace 在表达式的上、下方给出一水平的大括号</p>
<ul>
<li><span class="math inline">\(\underbrace{a+b+c+...+z}_{26个字母}\)</span> ：\underbrace{a+b+c+...+z}_{26个字母}</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/25/Unsupervised-Proxy-Selection-for-Session-based-Recommender-Systems/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/25/Unsupervised-Proxy-Selection-for-Session-based-Recommender-Systems/" class="post-title-link" itemprop="url">Unsupervised Proxy Selection for Session-based Recommender Systems</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-11-25 21:10:16" itemprop="dateCreated datePublished" datetime="2021-11-25T21:10:16+08:00">2021-11-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-11-29 21:25:30" itemprop="dateModified" datetime="2021-11-29T21:25:30+08:00">2021-11-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>   由于Session-based Recommender Systems（SRS）中缺少用户相关信息，所以很难直接从数据中获得用户的整体兴趣。因此，现有的SRS侧重于如何在会话中有效地建模有关短期兴趣的信息，但它们不足以捕获用户的整体兴趣。为此，作者提出了一个新的框架来克服SRS的局限性，名为ProxySR，它通过对会话代理进行建模来模拟SRS中缺失的信息（即用户的整体兴趣）。<br />
   ProxySR以无监督的方式为输入的会话选择一个合适的proxy，将其与从该会话提取的短期兴趣结合，用于next item prediction。此外，作者还提出了SRS的另一种现实情况，即少数用户登录并在会话中留下他们的标识符，并针对这种情况修改了ProxySR。<br />
   ProxySR模型设计的初衷来源于以下总体兴趣的特征：</p>
<ul>
<li>多个会话可能具有相似的用户总体兴趣（比如，这多个会话是由同一个用户创建的，且该用户具备稳定的总体兴趣）</li>
<li>除了短期兴趣外，总体兴趣也可以弥补会话推荐中丢失的信息，以帮助预测下一个交互的item</li>
</ul>
<h2 id="methond">Methond</h2>
<figure>
<img src="figure1.png" alt="图1 ProxySR的总体架构" /><figcaption aria-hidden="true">图1 ProxySR的总体架构</figcaption>
</figure>
<h3 id="proxy-selection"><strong>Proxy Selection</strong></h3>
<p>  ProxySR首先通过输入的session <span class="math inline">\(s\)</span> 构建偏态概率分布，进而从预先定义的K个proxy embeddings选择一个proxy embedding。更具体地说，ProxySR利用encoder network生成概率的对数，然后通过用具有温度参数的softmax函数将其转换为偏态概率分布 <span class="math inline">\(\pi \in \mathbb{R}^K\)</span> ，如下所示：<br />
<span class="math display">\[\boldsymbol\alpha=f^P(s)\]</span> <span class="math display">\[\boldsymbol{\pi_i}={exp(\boldsymbol{\alpha_i}/\tau)\over \sum_{j=1}^Kexp(\boldsymbol{\alpha_j}/\tau)} \ for\ i\in(1,2,...,K) \tag{1}\label{eq1}\]</span> 其中 <span class="math inline">\(f^P\in\mathbb{R}^K\)</span>是对于session <span class="math inline">\(s\)</span> 的 encoder network。𝐾为Proxy数量，<span class="math inline">\(\boldsymbol{\pi_i}\)</span>是第i个Proxy的概率。<span class="math inline">\(\tau&gt;0\)</span>是温度参数。当<span class="math inline">\(\tau\)</span>越小，<span class="math inline">\(\boldsymbol\pi\)</span>变成一个接近one-hot向量的分布。当<span class="math inline">\(\tau\)</span>越大，<span class="math inline">\(\boldsymbol\pi\)</span>变成一个每个元素接近1/K的均匀分布。因此，作者将一个较大的初始值指定给𝜏 并随着训练的进行而减小，因为如果𝜏 很小，梯度会偏向于少数对数，这对于不稳定的初始训练是不可取的。最后获得session <span class="math inline">\(s\)</span>的proxy embedding <span class="math inline">\(p^{(s)}\)</span><br />
<span class="math display">\[
\gamma={\sum_{j=1}^K\Vert\boldsymbol{\pi_j}P_j\Vert_2\over \Vert\sum_{j=1}^K\boldsymbol{\pi_j}P_j\Vert_2}
\]</span> <span class="math display">\[p^{(s)}=\gamma\sum_{j=1}^k\boldsymbol{\pi_j}P_j\tag{2}\]</span></p>
<p>其中 <span class="math inline">\(P\in\mathbb{R}^{K\times d}\)</span> 是proxy embedding matrix。<span class="math inline">\(\tau\)</span> 经过几次训练后已经足够小了，因此 <span class="math inline">\(\pi\)</span> 变为一个one-hot vector，并且仅从集合中选择一个proxy embedding。<br />
  当<span class="math inline">\(\tau\)</span>在初始训练阶段较大时，获得的代理的规模可能太小，因为每个proxy都是以均值为 0 随机初始化的，并均匀聚合以相互抵消。因此，作者通过使用 <span class="math inline">\(\gamma\)</span> 重新缩放获得的proxy来防止这个问题，这迫使其 <span class="math inline">\(\mathcal{l}_2\)</span> 范数保持proxies的 <span class="math inline">\(\mathcal{l}_2\)</span>范数的加权平均值。</p>
<h4 id="boldsymbolfps实现细节"><strong><span class="math inline">\(\boldsymbol{f^P(s)}\)</span>实现细节</strong></h4>
<p>  encoder network如下<br />
<span class="math display">\[f^P(s)={1\over n} \sum_{j=1}^nW^{P,(2)^T}\sigma\left(W^{P,(1)^T}\left(I_{s_j}+E_j^P\right)\right)\tag{3}\label{eq3}\]</span><br />
其中，<span class="math inline">\(I_{s_j}\)</span>是session <span class="math inline">\(s\)</span>中第j个item的embedding。<span class="math inline">\(E_j^P\)</span>是对于位置j的learnable positional embedding。<span class="math inline">\(W^{P,(1)^T}\in\mathbb{R}^{d\times\lfloor (d+K)/2\rfloor }\)</span>,<span class="math inline">\(W^{P,(2)^T}\in\mathbb{R}^{\lfloor (d+K)/2\rfloor \times K }\)</span> 为权重矩阵。<span class="math inline">\(\sigma\)</span>为负斜率为0.1的Leaky ReLU。<br />
  注意,在训练阶段，作者使用了全部的session item来选择proxy，而在预测next item <span class="math inline">\(s_t\)</span>时只使用了<span class="math inline">\([s_1,s_2,...s_{t-1}]\)</span></p>
<h4 id="discussion"><strong>Discussion</strong></h4>
<p>  作者讨论了为什么不使用普通的softmax将多个proxies加权生成对应session的proxy。作者认为，对多个proxies的加权组合会为每个session创建一个独一无二的proxy,这相当于对session encoder 为representation。但是，只从单个session 中很难提取整体兴趣。因此不能保证加权结合能够对多个sessions中的公共整体兴趣建模。而ProxySR选择的是最有可能的一个proxy，因此选择的proxy能够在多个session之间共享，进而能捕捉这些sessions之间的共同信息。</p>
<h3 id="short-term-interest-encoder"><strong>Short-term Interest Encoder</strong></h3>
<p>  session 中本身包含短期兴趣，因此直接将session encoder 为隐表示作为short-term interest <span class="math inline">\(s^{(s)}\)</span><br />
<span class="math display">\[
s^{(s)}=f^S(s)\tag{4}\label{eq4}
\]</span> 其中<span class="math inline">\(f^S(s)\in\mathbb{R}^d\)</span>为encoder network。<span class="math inline">\(s^{(s)}\in\mathbb{R}^d\)</span> 为session <span class="math inline">\(s\)</span>包含的short-term interest的表示。</p>
<h4 id="boldsymbolfss实现细节"><strong><span class="math inline">\(\boldsymbol{f^S(s)}\)</span>实现细节</strong></h4>
<p>  考虑items之间的依赖关系，作者使用具有残差连接的自注意力网络。 <span class="math display">\[X=[I_{s_1}+E_n^S,I_{s_2}+E_{n-1}^S,...,I_{s_n}+E_1^S]^T \]</span> <span class="math display">\[Q=ReLU(XW^{S,(Q)})\]</span> <span class="math display">\[K=ReLU(XW^{S,(K)})\]</span> <span class="math display">\[A=softmax({QK^T\over\sqrt d })\]</span> <span class="math display">\[Z=AX+X \]</span> <span class="math display">\[f^S(s)=W^{S,(2)^T}ReLU\left(W^{S,(1)^T}Z+b^{S,(1)}\right)+b^{S,(2)}\tag{5}\label{eq5}\]</span> 其中<span class="math inline">\(E_j^S\)</span>为逆序的learnable positional embedding。<span class="math inline">\(X\in\mathbb{R}^{n\times d};W^{S,(Q)},W^{S,(K)},W^{S,(1)},W^{S,(2)}\in\mathbb{R}^{d\times d};b^{S,(1)},b^{S,(2)}\in\mathbb{R}^d\)</span></p>
<h3 id="combination"><strong>Combination</strong></h3>
<p>  该部分将为session s选择好的proxy <span class="math inline">\(p^{(s)}\)</span>和其短期兴趣<span class="math inline">\(s^(s)\)</span>结合到一起，获得会话s的最终表示，然后再用该表示计算该session和目标item i之间相异性得分。然而，根据一些先例研究，简单的加法不能模拟比一对一关系更复杂的三元组内的关系。</p>
<ul>
<li>情景1：如果同一个item与两个不同和短期兴趣、同一个selected proxy相关，那么模型可能会认为这两个不同的短期兴趣是相似的，即if <span class="math inline">\(p + s^{(1)} ≈ I_i\)</span> and <span class="math inline">\(p + s^{(2)} ≈ I_𝑖\)</span> then $ s^{(1)} ≈ s^{(2)}$</li>
<li>情景2：如果两个不同的item与同一个proxy相关，且分别与两个相似的短期兴趣相关，那么模型会认为这两个不同的item是相似的，即 if <span class="math inline">\(p + s^{(1)} ≈ I𝑖^{(1)}\)</span> and <span class="math inline">\(p + s^{(2)} ≈ I_i^{(2)}\)</span> where <span class="math inline">\(s^{(1)} ≈ s^{(2)}\)</span>, then <span class="math inline">\(I_i^{(1)} ≈ I_i^{(2)}\)</span></li>
</ul>
<p>因此，作者借鉴TransH的思想，将短期兴趣和目标item的embedding投影到超平面（hyperplane），以捕获三元组间复杂的关系。具体来说，首先获得投影到超平面的short-term interest <span class="math inline">\(s_\perp ^{(s)}\)</span>以及目标 item embedding <span class="math inline">\(I_{i\perp}\)</span> <span class="math display">\[
\boldsymbol{v}={\sum_{j=1}^K\Vert\boldsymbol{\pi_j}V_j\Vert_2\over \Vert\sum_{j=1}^K\boldsymbol{\pi_j}V_j\Vert_2}
\]</span> <span class="math display">\[s_\perp ^{(s)}=s^{(s)}-\boldsymbol{v}^Ts^{(s)}\boldsymbol{v}\]</span> <span class="math display">\[I_{i\perp}=I_i-\boldsymbol{v}^TI_i\boldsymbol{v}\]</span> <span class="math inline">\(V\in\mathbb{R}^{K\times d}\)</span> 是proxy hyperplanes的单位法向量set。<span class="math inline">\(\boldsymbol{v}\in\mathbb{R}^d\)</span>是投影到<span class="math inline">\(p^{(s)}\)</span>的超平面的单位法向量。为了使法向量与proxy的超平面正交并具有单位长度，作者约束<span class="math inline">\(\lvert v\cdot p^{(s)}\rvert/\Vert p^{(s)}\Vert_2 \le \epsilon\)</span> , <span class="math inline">\(\Vert V_j\Vert_2=1\)</span><br />
  最后，会话 𝑠 和目标item 𝑖 之间的相异性分数是通过预测的item embedding与proxy的聚合以及预测的短期兴趣之间的距离来估计的。计算相异性分数如下： <span class="math display">\[dist(s,i)=\left\Vert\left(p^{(s)}+s_\perp^{(s)}\right)-I_{i\perp}\right\Vert_2^2\tag{7}
\]</span></p>
<h3 id="training"><strong>Training</strong></h3>
<p>  采用 marginal loss 训练模型。采用单位法向量 v 的正交正则器orthogonality regularizer和distance regularizer，强制会话表示接近目标item embbedng.<br />
  首先定义损失函数<span class="math inline">\(\mathcal{L}\)</span> <span class="math display">\[\mathcal{L}=\sum_{\{s,i^+\}\in \boldsymbol S}\sum_{i^-\in NI(s)}[m+dist(s,i^+)-dist(s,i^-)]_+\tag{8}
\]</span> <span class="math inline">\(i^+\)</span> 为session s的true next item, <span class="math inline">\(NI(s)\subset I\backslash i^+\)</span> 是session s 的 negative items 集。<span class="math inline">\([x]_+=max(x,0)\)</span>。𝑚 is the margin。<br />
  包括正则化项，最终的最小化目标函数J定义为如下所示：<br />
<span class="math display">\[reg^{dist}=\sum_{\{s,i^+\}\in \boldsymbol S}dist(s,t^+)\]</span> <span class="math display">\[reg^{orthog}=\sum_{\{s,i^+\}\in \boldsymbol S}{\rvert v^{(s)}\cdot p^{(s)}\rvert\over \Vert p^{(s)}\Vert_2}\]</span> <span class="math display">\[\mathcal{J}=\mathcal{L}+\lambda^{dist}\cdot reg^{dist}+\lambda^{orthog}\cdot reg^{orthog}\tag{9}\]</span></p>
<h3 id="another-real-world-case-user-semi-supervision"><strong>Another Real-world Case: User Semi-supervision</strong></h3>
<p>作者还考虑了当数据集中存在部分用户信息的时候，如何利用这些用户信息进行半监督学习。即在生成proxy的概率分布时加入user bias，对于缺少用户信息的session,仍按初始的方式计算proxy的概率<span class="math inline">\(\eqref{eq1}\)</span>： <span class="math display">\[\boldsymbol{\pi_i}^{user}={exp\left(\left(\boldsymbol{\alpha_i}+u_j^{(s)}\right)/\tau\right)\over \sum_{j=1}^Kexp\left(\left(\boldsymbol{\alpha_j}+u_j^{(s)}\right)/\tau\right)} \ for\ i\in(1,2,...,K) \tag{10}\label{eq10}\]</span><br />
其中<span class="math inline">\(u^{(s)}\in\mathbb{R}^K\)</span> 是对于session s的用户可学习user bias。</p>
<h2 id="experiments">EXPERIMENTS</h2>
<h3 id="datasets"><strong>datasets</strong></h3>
<center>
表1 Statistics of datasets
</center>
<p><img src="table1.png" /></p>
<p>实验包含两个任务：</p>
<ul>
<li>next unseen item recommendation</li>
<li>next item recommendation with repetitive consumption.</li>
</ul>
<h3 id="performance-comparison"><strong>Performance Comparison</strong></h3>
<center>
表2 Overall performance on the next unseen item recommendation
</center>
<p><img src="table2.png" /></p>
<center>
表3 Overall performance on the next item recommendation with repetitive consumption
</center>
<p><img src="table3.png" /></p>
<p>ProxySR与CSRM和GCE-GNN的比较证明，基于item co-occurrence的相邻会话的信息不足以捕获会话的一般兴趣。 ProxySR在短序列的数据集更有效。如在RetailRocket数据集上提升最大。在LastFM数据集上提升最小。</p>
<center>
表4 Performance of ProxySR in the real-world scenario where a few sessions have their user information
</center>
<p><img src="table4.png" /></p>
<h3 id="消融实验"><strong>消融实验</strong></h3>
<center>
表5 Result of the ablation study on each component in ProxySR
</center>
<p><img src="table5.png" /></p>
<h3 id="hyperparameter-study"><strong>Hyperparameter Study</strong></h3>
<img src="figure3.png" title="fig:" alt="图2" />
<center>
图2 Result of the hyperparameter parameter study on 𝐾 in ProxySR.
</center>
<h3 id="analyses-on-proxies-from-proxysr"><strong>Analyses on Proxies from ProxySR</strong></h3>
<h4 id="information-encoded-in-proxies"><strong>Information Encoded in Proxies</strong></h4>
<center>
表6 Performance of HRNN with various types of the user information in it
</center>
<p><img src="table6.png" /><br />
  HRNN通过user-level RNN，顺序使用用户会话来训练user embedding。</p>
<h4 id="visualizations"><strong>Visualizations</strong></h4>
使用t-分布领域嵌入（t-SNE）来可视化高维表示。图3展示了与10个随机用户相关的session表示可视化，相同颜色的圆圈表示该session属于同一个user。 <img src="figure4.png" alt="图3" /><br />

<center>
图3 Visualizations of several representations related to sessions
</center>
<p>从图3可以发现：</p>
<ul>
<li>有些proxy是由多个用户的会话选择的，这是因为多个用户可能有相似的一般兴趣（多种颜色聚集的一团）</li>
<li>多个proxies被相同用户的session选择，说明proxy可以对比用户一般兴趣更细粒度的信息进行建模。（浅蓝色那一团）</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/16/Learning-Feature-Interactions-with-Lorentzian-Factorization-Machine/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/16/Learning-Feature-Interactions-with-Lorentzian-Factorization-Machine/" class="post-title-link" itemprop="url">Learning Feature Interactions with Lorentzian Factorization Machine</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-11-16 17:02:14" itemprop="dateCreated datePublished" datetime="2021-11-16T17:02:14+08:00">2021-11-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-11-27 20:05:28" itemprop="dateModified" datetime="2021-11-27T20:05:28+08:00">2021-11-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">推荐系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="摘要">摘要</h2>
<p>    学习特征交互的表示以模拟用户行为对于推荐系统和点击率（CTR）预测至关重要。深度学习方法能够学习复杂的特征交互,但是这些方法需要大量与low-level representations相结合的训练参数，因此内存和计算效率都很低。</p>
<p>   作者提出了一个名为“LorentzFM”的新模型，该模型可以学习嵌入在双曲空间（hyperbolic space）中的特征相互作用，在双曲空间中，Lorentz距离的三角不等式的破坏是可实现的。双曲三角形的特殊几何特性对学习特征交互的表示是有益的。并且因为不需要任何顶部深度学习层，参数数量显著减少（20%至80%）。</p>
<p>  作者提出在使用Lorentz距离的双曲空间中学习低维表示，这样就能违反特征向量的三角不等式。该想法是受collaborative metric learning (CML) (Hsieh et al. 2017) 工作的启发。不同的是，CML作者认为欧氏空间中的三角形不等式应该严格遵守，本文作者提出利用三角形不等式的符号。具体地说，本文作者不是通过特征向量之间的内积或距离，而是通过检查它们在双曲空间中形成的三角形来构造特征交互的分数函数。采取这种做法的原因有两个方面：<br />
    1.双曲空间本质上比欧几里德空间更广阔；<br />
    2.提出的分数函数将提供一个鲁棒的目标函数来学习细粒度特征交互。</p>
<h2 id="技术背景">技术背景</h2>
<h3 id="双曲几何hyperbolic-geometry"><strong>双曲几何(Hyperbolic Geometry)</strong></h3>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/baiting/p/11006331.html">推荐阅读</a><br />
   双曲几何旨在研究具有常数负曲率的非欧几里德空间。由于其负曲率，双曲几何与欧几里德几何相比具有非常不同的性质。<br />
   首先，与欧几里德空间中的线性和二次增长率相反，双曲空间中圆的周长和面积随半径呈指数增长。因此，在半径上界相同的双曲空间中嵌入的容量比欧几里德空间中嵌入的容量大得多。其次，定义在洛伦兹距离下的三角不等式是可以违反。这个性质使我们能够用不等式的符号来刻画双曲空间中点之间的成对关系。（双曲空间有几个重要的计算模型： the Poincare ball model, the hyper-boloid model, the Klein model）<br />
<strong>Hyperboloid Model</strong><br />
  定义 <span class="math inline">\(\textbf{u},\textbf{v}\in \mathbb{R}^{n+1}\)</span> 之间的洛伦兹内积如下：<br />
<span class="math display">\[\langle \textbf{u},\textbf{v} \rangle_{\mathcal{L}} = -u_0v_0+\sum_{i=1}^nu_iv_i\tag{1} \label{eq1} \]</span>   n维双曲面 <span class="math inline">\(H^{n,\beta}\subseteq\mathbb{R}^{n+1}\)</span>由以下定义的点集组成：</p>
<p><span class="math display">\[H^{n,\beta}=\lbrace\textbf{x}\in \mathbb{R}^{n+1}:\Vert \textbf{x} \Vert_{\mathcal{L}}^2=-\beta,x_0&gt;\beta \rbrace \tag{2} \label{eq2}\]</span></p>
<p>  <span class="math inline">\(\Vert \textbf{x} \Vert_{\mathcal{L}}^2=\langle \textbf{x},\textbf{x} \rangle_{\mathcal{L}}\)</span> 表示向量X的洛伦兹范数。在此定义下，每个向量 <span class="math inline">\(\textbf{x}\in H^{n,\beta}\)</span> 的第0维度 <span class="math inline">\(x_0\)</span> 不能随意指定，应由以下公式定义： <span class="math display">\[x_0=\sqrt{\beta+\sum_{i=1}^n x_i}\tag{3} \label{eq3}\]</span>   两点之间的相关测地距离为:<br />
<span class="math display">\[d_l( \textbf{u},\textbf{v})=arccosh(-\langle\textbf{u},\textbf{v}\rangle_{\mathcal{L}}) \tag{4}\label{eq4}\]</span><br />
  请注意，双曲面模型 <span class="math inline">\(H^{n,\beta}\)</span> 的原点向量为 <span class="math inline">\(\boldsymbol{0}=(\beta,0,...,0)\)</span> 并且 <span class="math inline">\(\boldsymbol{0}\)</span> 与任意向量 <span class="math inline">\(\textbf{x}\in \mathbb{R}^{n+1}\)</span> 的洛伦兹内积定义为 <span class="math inline">\(\langle\textbf{0},\textbf{x}\rangle=-x_0&lt;\beta\)</span>.这里原点向量的定义和原点向量与其他向量的内积应该是特殊定义，因为它们分别不满足等式 <span class="math inline">\(\eqref{eq2}\)</span> 和 <span class="math inline">\(\eqref{eq1}\)</span><br />
  当 <span class="math inline">\(\beta=1\)</span>时，该模型称为单位双曲面模型（unit Hyperboloid Model）。这将贯穿整个论文，并且将 <span class="math inline">\(H^{n,1}\)</span> 简记为 <span class="math inline">\(H^{n}\)</span>。</p>
<p><strong>Lorentz Distance</strong><br />
  <span class="math inline">\(\textbf{u}\)</span> , <span class="math inline">\(\textbf{v} \in H^n\)</span> 之间的平方洛伦兹距离（简称洛伦兹距离）定义如下：<br />
<span class="math display">\[d_{\mathcal{L}}^2(\textbf{u},\textbf{v})=\Vert \textbf{u}-\textbf{v}\Vert_{\mathcal{L}}^2=-2-2\langle\textbf{u},\textbf{v}\rangle_{\mathcal{L}}\tag{5}\label{eq5}\]</span><br />
  它几乎满足欧几里得几何的所有公理，但是不满足三角不等式。三角不等式是正定黎曼度量的最关键几何性质之一，它表明对于任意三个点 <span class="math inline">\(\textbf{x}\)</span>,<span class="math inline">\(\textbf{y}\)</span>,<span class="math inline">\(\textbf{z}\)</span>，任意两对点之间的距离<span class="math inline">\(d(.,.)\)</span>的和大于或等于剩下一个点对之间的距离。 <span class="math display">\[d(\textbf{x},\textbf{y})\leq d(\textbf{x},\textbf{z})+d(\textbf{z},\textbf{y})\tag{6}\label{eq6}\]</span>   在双曲空间中，公式<span class="math inline">\(\eqref{eq4}\)</span>定义的测地距离满足此不等式，但是在洛伦兹距离<span class="math inline">\(\eqref{eq5}\)</span>下,可能不满足此不等式，因为黎曼度量是负的。考虑原点和两个点<span class="math inline">\(\textbf{u}\)</span>,<span class="math inline">\(\textbf{v}\)</span>组成的三角形，如图1所示。当两个点在<span class="math inline">\(x_1\)</span>轴不同边相距很远时，违反了三角不等式。如果两个点在同<span class="math inline">\(x_1\)</span>轴一边，三角不等式成立。</p>
<img src="triangle.png" alt="图一" /><br />

<center>
图1 (a)违反了三角不等式,（b）满足三角不等式 <span class="math inline">\(\label{pic1}\)</span>
</center>
<h3 id="learning-triangle-inequalities"><strong>Learning Triangle Inequalities</strong></h3>
  Hsieh et al. (2017)指出学习嵌入空间中的距离而不是内积有利于学习细粒度的嵌入空间，该空间不仅可以捕获item-user交互的表示，还可以捕获item-item和user-user距离的表示。本质上，所谓的度量学习方案(metric learning scheme)受到三角不等式的约束。<br />
  与协同度量学习方案相反，作者认为两点之间的特征交互可以通过洛伦兹距离的三角不等式的符号来学习，而不是使用距离本身。形式上，score function写为： <span class="math display">\[
\mathcal{T}(\textbf{x},\textbf{y})={d_{\mathcal{L}}^2(\textbf{x},\textbf{y})-d_{\mathcal{L}}^2(\textbf{x},\textbf{0})-d_{\mathcal{L}}^2(\textbf{0},\textbf{y}) \over \langle\textbf{0},\textbf{x}\rangle_{\mathcal{L}}\langle\textbf{0},\textbf{y}\rangle_{\mathcal{L}}}\tag{7}\label{eq7}
\]</span><br />
分子为不等式两边的差，分母是为了约束score function.<br />
  该score function 对于所有的维度，取值范围均为[-0.5,2].因此，与协同度量学习方案相比，分数函数不受维度的影响。如图2（a），为了说明函数的布局，绘制了等式（7）在2D中两点的取值。<br />
<img src="2D.jpg" alt="图2" /><br />

<center>
图2 （a）triangle learning方案（例如，等式 <span class="math inline">\(\eqref{eq7}\)</span> ）和（b）在二维双曲面模型中使用测地距离的度量学习方案中分数函数的二维图
</center>
<p>因为二维双曲模型中的点只有一个自由参数（参考<span class="math inline">\(\eqref{eq3}\)</span>），因此图中的x轴和y轴分别表示两个点的自由参数。同时，作者使用等式<span class="math inline">\(\eqref{eq4}\)</span>中定义的测地距离绘制了协同度量学习方案的取值图2（b）。通过比较，可以观察到作者提出的方法的取值是平滑和有界的，但是协作度量学习方案的得分函数取值是无界的。有界性是有用的，因为嵌入向量可以自由地远离原点，而分数函数仍可以平滑增长。</p>
<h2 id="lorentzian-factorization-machine">Lorentzian Factorization Machine</h2>
<h3 id="overview"><strong>Overview</strong></h3>
<img src="pic3.jpg" alt="图3" /><br />

<center>
图3 LorentzFM结构图
</center>
<p>  如图三所示，稀疏特征向量<span class="math inline">\(\mathcal{V}_x\)</span>作为模型输入。经过Lorentz embedding layer，将所有特征投影到同一个双曲空间。接下来，将所有字段的嵌入引入一个新的triangle pooling层，该层作为所有特征对的聚合函数，从整体上度量三角形不等式的 soft “validness” 。与最近建立在欧几里德嵌入基础上的最先进的神经结构不同，LorentzFM不需要任何额外的参数。特别是，对于给定的稀疏输入<span class="math inline">\(V_x\)</span>，池化层的输出是模型输出分数<br />
<span class="math display">\[\hat{S}_{LFM}(\mathcal{V}_x)=\sum_{i,j=1,i\neq j}^d \mathcal{T} (\textbf{v}_i,\textbf{v}_j)x_ix_j \tag{8}\label{eq8} \]</span><br />
其中<span class="math inline">\(\textbf{v}_i,\textbf{v}_j \in H^n\)</span>是每个输入特征字段的嵌入向量。<span class="math inline">\(\mathcal{T}(.,.)\)</span>是特征交互函数。虽然在公式（8）中形式上缺少线性项，但它实际上在池函数<span class="math inline">\(\mathcal{T}(.,.)\)</span>中重新出现，如下文所示。（为什么作者强调要有线性项）</p>
<h3 id="lorentz-embedding-layer"><strong>Lorentz Embedding Layer</strong></h3>
<p>  嵌入层是一个lookup操作，用于将稀疏特征投影到洛伦兹空间中的低维密集向量。即<span class="math inline">\(\textbf{v}_k\in H^n\)</span>是第k个特征的嵌入向量，而第0个分量由等式<span class="math inline">\(\eqref{eq3}\)</span>中的约束给出。<br />
  在某些情况下，分类特征可以是多值的。例如，电影《泰坦尼克号》的类型可以是“Drama”或“Romance”。因此为这些分类特征使用多个字段，并用“unknown”填充它们，以确保每个样本在特征维度上对齐。</p>
<h3 id="triangle-pooling-layer"><strong>Triangle Pooling Layer</strong></h3>
<p>  Pooling 层是一个聚合函数，用于将一组嵌入向量转换为一个向量： <span class="math display">\[
\mathcal{T}(\textbf{u},\textbf{v})={d_{\mathcal{L}}^2(\textbf{u},\textbf{v})-d_{\mathcal{L}}^2(\textbf{u},\textbf{0})-d_{\mathcal{L}}^2(\textbf{0},\textbf{v}) \over 2\langle\textbf{0},\textbf{u}\rangle_{\mathcal{L}}\langle\textbf{0},\textbf{v}\rangle_{\mathcal{L}}}
\]</span> <span class="math display">\[
={1-\langle\textbf{u},\textbf{v}\rangle_{\mathcal{L}}-u_0-v_0 \over u_0v_0}
\]</span> <span class="math display">\[
={1-\langle\textbf{u},\textbf{v}\rangle_{\mathcal{L}} \over 2u_0v_0}-\left({1\over u_0}+{1\over v_0}\right)\tag{9}\label{eq9}
\]</span></p>
<p>由于标准化分母，出现了线性项，如公式最后一行<span class="math inline">\(\left({1\over u_0}+{1\over v_0}\right)\)</span>所示。</p>
<h3 id="objective-and-learning"><strong>Objective and Learning</strong></h3>
<p>  推荐系统和CTR预测的目标函数是二元交叉熵（BCE）： <span class="math display">\[
\arg\,\min_{\theta}\sum_i-y_ilog(p_i)-(1-y_i)log(1-p_i)\tag{10}\label{eq10}
\]</span> i表示第i个样本，其中<span class="math inline">\(p_i=\sigma\left(\hat{S}_{LFM}\left(\mathcal{V}_x^i\right)\right)\)</span>,为第i输入样本<span class="math inline">\(\mathcal{V}_x^i\)</span>的（点击）可能性。<span class="math inline">\(y_i\)</span>是真实标签。作者指出，尽管贝叶斯个性化排名（Bayesian Personalized Ranking, BPR）损失（Rendle et al.2009）在普遍的推荐系统中被证明是有用的，但作者不使用它，因为BCE损失是符号敏感的，这是期望的属性，而BPR损失不是。<br />
  模型参数是通过使用黎曼随机梯度下降法（RSGD）（Bonnabel 2013）学习的。如Nickel和Kiela（2018）提到的，参数更新方式如下所示： <span class="math display">\[
\theta_{t+1}=exp_{\theta_t}(-\eta\ grad\ f(\theta_t))\tag{11}\label{eq11}
\]</span> 其中，<span class="math inline">\(grad\ f(\theta_t)\)</span>是黎曼流形中定义的梯度，<span class="math inline">\(\eta\)</span>是学习率。黎曼梯度是通过将欧几里德空间中的梯度乘以洛伦兹度量，然后在当前参数集跨越的切线空间上执行正交投影来获得的。最后，通过以下指数映射给出参数更新: <span class="math display">\[
exp_{\theta_t}(\textbf{x})=cosh(\Vert\textbf{v}\Vert_{\mathcal{L}})\textbf{x}+sinh(\Vert\textbf{v}\Vert_{\mathcal{L}}){\textbf{v}\over \Vert\textbf{v}\Vert_{\mathcal{L}}}\tag{12}\label{eq12}
\]</span> 它将切线空间中的切线向量v映射到洛伦兹流形上。详细信息见Nickel and Kiela（2018） Learning continuous hierarchies in the lorentz model of hyperbolic geometry。(待学习)<br />
  由于score function等式<span class="math inline">\(\eqref{eq7}\)</span>是有界且与维度无关的，因此无需在嵌入向量上应用L2正则化项，因为它会对双曲面模型的原点创造一个抵抗梯度。</p>
<h2 id="实验">实验</h2>
<img src="table1.jpg" title="fig:" alt="表1" />
<center>
表1 数据预处理后的数据集统计。在Avazu数据集中，itemID和userID没有明确的指示符，因此将相应的行留空。
</center>
<p>Steam, MovieLens and KKBox数据集用于推荐任务，Avazu用于CTR任务。</p>
<img src="table2.jpg" title="fig:" alt="表2" />
<center>
表2 每个模型在测试集上的最佳性能。
</center>
<p>从表2可发现， 除了MovieLens数据集，LorentzFM的效果比其他模型都好。原因是MovieLens的稀疏特征的数量是其他数据集的5到100倍，说明当数据非常稀疏时，LorentzFM功能尤其强大。</p>
<img src="table3.jpg" title="fig:" alt="表3" />
<center>
表3 在最佳性能下，每个模型的训练参数数量与训练时间比较表。
</center>
<img src="figure5.jpg" title="fig:" alt="图5" />
<center>
图5 Visualization of the heatmap of score functions from LorentzFM for (a) a positive sample and (b) a negative sample, and from FM for the same (c) positive sample and (d) negative sample
</center>
<p>  作者选了一个典型的用户(user ID “76561198071045315”)。该用户几乎所有正评分都是Steam中免费的游戏。针对该用户，作者画了图5。从图5(a)中可以发现，对于游戏是免费的正样本，由LorentzFM学习到的“UserID” 和 “Price”的特征交互分数达到了最高0.4。说明用户非常倾向于免费的物品。而从图5（c）并不能得到该信息。<br />
  对于游戏价格为$14.99的负样本，由LorentzFM学习到的“UserID” 和 “Price”的特征交互分数几乎是最低的负数。这意味着负样本主要是由于其价格而被识别的。而FM中“UserID” 和 “Price” 的内积结果并不占主要地位。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/15/Multi-Interactive-Attention-Network-for-Fine-grained-Feature-Learning-in-CTR-Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/15/Multi-Interactive-Attention-Network-for-Fine-grained-Feature-Learning-in-CTR-Prediction/" class="post-title-link" itemprop="url">Multi-Interactive Attention Network for Fine-grained Feature Learning in CTR Prediction</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-11-15 13:27:18" itemprop="dateCreated datePublished" datetime="2021-11-15T13:27:18+08:00">2021-11-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/11/15/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="yogattt">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hello World">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/11/15/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-11-15 11:08:04" itemprop="dateCreated datePublished" datetime="2021-11-15T11:08:04+08:00">2021-11-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-11-16 18:08:52" itemprop="dateModified" datetime="2021-11-16T18:08:52+08:00">2021-11-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hexo%E4%BD%BF%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">hexo使用</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="yogattt"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">yogattt</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yogattt</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<!-- 樱花特效 -->
  
</body>
</html>
